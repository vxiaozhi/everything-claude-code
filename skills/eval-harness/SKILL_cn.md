# 评估工具技能

Claude Code 会话的正式评估框架，实施评估驱动开发 (EDD) 原则。

## 哲学

评估驱动开发将评估视为"AI 开发的单元测试"：
- 在实施之前定义预期行为
- 在开发期间持续运行评估
- 跟踪每次更改的回归
- 使用 pass@k 指标进行可靠性测量

## 评估类型

### 能力评估
测试 Claude 是否能做以前不能做的事情：
```markdown
[能力评估：feature-name]
任务：Claude 应该完成的事情的描述
成功标准：
  - [ ] 标准 1
  - [ ] 标准 2
  - [ ] 标准 3
预期输出：预期结果的描述
```

### 回归评估
确保更改不会破坏现有功能：
```markdown
[回归评估：feature-name]
基线：SHA 或检查点名称
测试：
  - existing-test-1: 通过/失败
  - existing-test-2: 通过/失败
  - existing-test-3: 通过/失败
结果：X/Y 通过（之前 Y/Y）
```

## 评估器类型

### 1. 基于代码的评估器
使用代码的确定性检查：
```bash
# 检查文件是否包含预期模式
grep -q "export function handleAuth" src/auth.ts && echo "通过" || echo "失败"

# 检查测试是否通过
npm test -- --testPathPattern="auth" && echo "通过" || echo "失败"

# 检查构建是否成功
npm run build && echo "通过" || echo "失败"
```

### 2. 基于模型的评估器
使用 Claude 评估开放式输出：
```markdown
[模型评估器提示]
评估以下代码更改：
1. 它是否解决了所述问题？
2. 它结构良好吗？
3. 是否处理了边缘情况？
4. 错误处理是否适当？

分数：1-5（1=差，5=优秀）
推理：[解释]
```

### 3. 人工评估器
标记以供手动审查：
```markdown
[需要人工审查]
更改：更改的描述
原因：为什么需要人工审查
风险级别：低/中/高
```

## 指标

### pass@k
"k 次尝试中至少一次成功"
- pass@1：第一次尝试成功率
- pass@3：3 次尝试内的成功率
- 典型目标：pass@3 > 90%

### pass^k
"所有 k 次试验都成功"
- 更高的可靠性标准
- pass^3：3 次连续成功
- 用于关键路径

## 评估工作流

### 1. 定义（编码前）
```markdown
## 评估定义：feature-xyz

### 能力评估
1. 可以创建新用户帐户
2. 可以验证电子邮件格式
3. 可以安全地哈希密码

### 回归评估
1. 现有登录仍然有效
2. 会话管理未更改
3. 注销流程完好

### 成功指标
- 能力评估的 pass@3 > 90%
- 回归评估的 pass^3 = 100%
```

### 2. 实施
编写代码以通过定义的评估。

### 3. 评估
```bash
# 运行能力评估
[运行每个能力评估，记录通过/失败]

# 运行回归评估
npm test -- --testPathPattern="existing"

# 生成报告
```

### 4. 报告
```markdown
评估报告：feature-xyz
========================

能力评估：
  create-user:     通过 (pass@1)
  validate-email:  通过 (pass@2)
  hash-password:   通过 (pass@1)
  总计：         3/3 通过

回归评估：
  login-flow:      通过
  session-mgmt:    通过
  logout-flow:     通过
  总计：         3/3 通过

指标：
  pass@1: 67% (2/3)
  pass@3: 100% (3/3)

状态：准备审查
```

## 最佳实践

1. **在编码之前定义评估** - 强制对成功标准进行清晰思考
2. **频繁运行评估** - 尽早捕获回归
3. **随着时间的推移跟踪 pass@k** - 监控可靠性趋势
4. **尽可能使用代码评估器** - 确定性 > 概率性
5. **安全的人工审查** - 永远不要完全自动化安全检查
6. **保持评估快速** - 慢评估不会运行
7. **使用代码版本化评估** - 评估是一流工件
